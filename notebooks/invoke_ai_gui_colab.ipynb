{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "V78TAa3W-9WN"
   },
   "source": [
    "This colab notebook contains a set of models (six for now), so you can switch from one model to another. If you need a specific colab notebook for only one model, you can check it [here](https://github.com/Lycantant/invoke-ai-gui-colab). <br>\n",
    "Models available for this notebook : [SD 1.5](https://huggingface.co/runwayml/stable-diffusion-v1-5), [Seek.art MEGA v1](https://huggingface.co/coreco/seek.art_MEGA), [Openjourney](https://huggingface.co/prompthero/openjourney), [trinart characters 19.2m](https://huggingface.co/naclbit/trinart_characters_19.2m_stable_diffusion_v1), [Anything v3](https://huggingface.co/Linaqruf/anything-v3.0), and [Waifu Diffusion v1.4](https://huggingface.co/hakurei/waifu-diffusion-v1-4). <br>\n",
    "Not familiar with the prompt technique used in InvokeAi? Read [here](https://invoke-ai.github.io/InvokeAI/features/PROMPTS/). And also each model has a different prompt technique. So you should read the links above carefully before starting, so your time will not be wasted.\n",
    "\n",
    "---\n",
    "## Requirements\n",
    "1. Login to ngrok [here](https://dashboard.ngrok.com/login), and create authtoken [here](https://dashboard.ngrok.com/get-started/your-authtoken).\n",
    "2. Requires 13 Gb disk space on a [Google Drive](https://drive.google.com/drive/my-drive)\n",
    "3. Don't rush, launch code in each form below one by one.\n",
    "---\n",
    "####Visit my Github repo [here](https://github.com/Lycantant/invoke-ai-gui-colab/).\n",
    "Give a ‚≠ê if you like it üòÅ <br>\n",
    "Semoga beruntung üôÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqe0rPfs6wJ3"
   },
   "outputs": [],
   "source": [
    "# @title 01. Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "G5LfQaWe0bHK"
   },
   "outputs": [],
   "source": [
    "#@title 02. During this stage, Colab crashes, it's normal\n",
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-4vMQGrGXx8"
   },
   "outputs": [],
   "source": [
    "#@title 03. Installing [InvokeAi](https://github.com/invoke-ai/InvokeAI) { display-mode: \"form\" }\n",
    "%cd /home\n",
    "\n",
    "!git clone -n https://github.com/invoke-ai/InvokeAI.git\n",
    "%cd InvokeAI\n",
    "!git checkout tags/v2.2.5\n",
    "\n",
    "!ln -sf environments-and-requirements/environment-lin-cuda.yml environment.yml\n",
    "!ls -la\n",
    "\n",
    "%cd ..\n",
    "\n",
    "!git clone https://github.com/Lycantant/invoke-ai-gui-colab.git\n",
    "\n",
    "%cd invoke-ai-gui-colab\n",
    "\n",
    "%cp cross_attention_control.py ../InvokeAI/ldm/models/diffusion/cross_attention_control.py\n",
    "%cp globals.py ../InvokeAI/ldm/invoke/globals.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0z1VLnSGQyrx"
   },
   "outputs": [],
   "source": [
    "#@title 04. Installation normally takes ~10 minutes { display-mode: \"form\" }\n",
    "%cd ../InvokeAI\n",
    "!pip install pyngrok --quiet\n",
    "!conda env update\n",
    "!source activate invokeai ; python scripts/configure_invokeai.py --yes\n",
    "\n",
    "%cp ../invoke-ai-gui-colab/models.yaml /root/invokeai/configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OzFl5cmndBrd"
   },
   "outputs": [],
   "source": [
    "#@title 05. Downloading of SD models (requires xx Gb disk space on a Google disk){ display-mode: \"form\" }\n",
    "import os\n",
    "\n",
    "os.system('cd /')\n",
    "os.system('mkdir -p /root/invokeai/models/ldm/stable-diffusion-v1')\n",
    "\n",
    "# sd 1.5\n",
    "if os.path.exists('/content/drive/MyDrive/models/v1-5-pruned-emaonly.ckpt'):\n",
    "    print('Model v1-5-pruned-emaonly.ckpt already exists')\n",
    "else:\n",
    "    print('Downloading Stable-Diffusion 1.5')\n",
    "    os.system('mkdir -p /content/drive/MyDrive/models/')\n",
    "    os.system('wget -O /content/drive/MyDrive/models/v1-5-pruned-emaonly.ckpt https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt')\n",
    "\n",
    "# seekArtMega_v1\n",
    "if os.path.exists('/content/drive/MyDrive/models/seekArtMega_v1-ckpt.ckpt'):\n",
    "  print('Model seekArtMega_v1-ckpt.ckpt already exists')\n",
    "else:\n",
    "  print('Downloading seekArtMega_v1-ckpt.ckpt')\n",
    "  os.system('wget -O /content/drive/MyDrive/models/seekArtMega_v1-ckpt.ckpt https://huggingface.co/coreco/seek.art_MEGA/resolve/main/seek_art_mega_v1.ckpt')\n",
    "\n",
    "# openjourney v4\n",
    "if os.path.exists('/content/drive/MyDrive/models/mdjrny-v4.ckpt'):\n",
    "  print('Model mdjrny-v4.ckpt already exists')\n",
    "else:\n",
    "  print('Downloading mdjrny-v4.ckpt')\n",
    "  os.system('wget -O /content/drive/MyDrive/models/mdjrny-v4.ckpt https://huggingface.co/prompthero/openjourney/resolve/main/mdjrny-v4.ckpt')\n",
    "\n",
    "# trinart_characters_19_2m\n",
    "if os.path.exists('/content/drive/MyDrive/models/trinart_characters_it4_v1.ckpt'):\n",
    "  print('Model trinart_characters_it4_v1.ckpt already exists')\n",
    "else:\n",
    "  print('Downloading trinart_characters_it4_v1.ckpt')\n",
    "  os.system('wget -O /content/drive/MyDrive/models/trinart_characters_it4_v1.ckpt https://huggingface.co/naclbit/trinart_characters_19.2m_stable_diffusion_v1/resolve/main/trinart_characters_it4_v1.ckpt')\n",
    "\n",
    "# vae trinart_characters_19_2m\n",
    "if os.path.exists('/content/drive/MyDrive/models/autoencoder_fix_kl-f8-trinart_characters.ckpt'):\n",
    "  print('Model autoencoder_fix_kl-f8-trinart_characters.ckpt already exists')\n",
    "else:\n",
    "  print('Downloading trinart_characters_19_2m vae')\n",
    "  os.system('wget -O /content/drive/MyDrive/models/autoencoder_fix_kl-f8-trinart_characters.ckpt https://huggingface.co/naclbit/trinart_characters_19.2m_stable_diffusion_v1/resolve/main/autoencoder_fix_kl-f8-trinart_characters.ckpt')\n",
    "\n",
    "# anything v3\n",
    "if os.path.exists('/content/drive/MyDrive/models/Anything-V3.0-pruned-fp16.ckpt'):\n",
    "  print('Model Anything-V3.0-pruned-fp16.ckpt already exists')\n",
    "else:\n",
    "  print('Downloading Anything-V3.0-pruned-fp16.ckpt')\n",
    "  os.system('wget -O /content/drive/MyDrive/models/Anything-V3.0-pruned-fp16.ckpt https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned-fp16.ckpt')\n",
    "\n",
    "# vae anything v3\n",
    "if os.path.exists('/content/drive/MyDrive/models/Anything-V3.0.vae.pt'):\n",
    "  print('Model Anything-V3.0.vae.pt already exists')\n",
    "else:\n",
    "  print('Downloading Anything-V3.0.vae.pt')\n",
    "  os.system('wget -O /content/drive/MyDrive/models/Anything-V3.0.vae.pt https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0.vae.pt')\n",
    "\n",
    "# vae\n",
    "if os.path.exists('/content/drive/MyDrive/models/vae-ft-mse-840000-ema-pruned.ckpt'):\n",
    "  print('Model vae-ft-mse-840000-ema-pruned.ckpt already exists')\n",
    "else:\n",
    "  print('Downloading SD-VAE')\n",
    "  os.system('wget -O /content/drive/MyDrive/models/vae-ft-mse-840000-ema-pruned.ckpt https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt')\n",
    "\n",
    "# if not not os.path.exists('/content/drive/MyDrive/models/vae-ft-mse-840000-ema-pruned.ckpt'):\n",
    "# heelllp, what does `if not not` mean? I'm not familiar with programming, especially python -_-\n",
    "if not os.path.exists('/content/drive/MyDrive/models/vae-ft-mse-840000-ema-pruned.ckpt'):\n",
    "    print('vae-ft-mse-840000-ema-pruned.ckpt doesn\\'t exist')\n",
    "else:\n",
    "    print('Make sure you accept the terms at https://huggingface.co/stabilityai/sd-vae-ft-mse-original')\n",
    "\n",
    "# sd 1.5\n",
    "!ln -s  /content/drive/MyDrive/models/v1-5-pruned-emaonly.ckpt /root/invokeai/models/ldm/stable-diffusion-v1/v1-5-pruned-emaonly.ckpt\n",
    "!ls -l /root/invokeai/models/ldm/stable-diffusion-v1/v1-5-pruned-emaonly.ckpt\n",
    "\n",
    "# seekArtMega v1\n",
    "!ln -s  /content/drive/MyDrive/models/seekArtMega_v1-ckpt.ckpt /root/invokeai/models/ldm/stable-diffusion-v1/seekArtMega_v1-ckpt.ckpt\n",
    "!ls -l /root/invokeai/models/ldm/stable-diffusion-v1/seekArtMega_v1-ckpt.ckpt\n",
    "\n",
    "# openjourney v4\n",
    "!ln -s  /content/drive/MyDrive/models/mdjrny-v4.ckpt /root/invokeai/models/ldm/stable-diffusion-v1/mdjrny-v4.ckpt\n",
    "!ls -l /root/invokeai/models/ldm/stable-diffusion-v1/mdjrny-v4.ckpt\n",
    "\n",
    "# trinart_characters_19_2m\n",
    "!ln -s  /content/drive/MyDrive/models/trinart_characters_it4_v1.ckpt /root/invokeai/models/ldm/stable-diffusion-v1/trinart_characters_it4_v1.ckpt\n",
    "!ls -l /root/invokeai/models/ldm/stable-diffusion-v1/trinart_characters_it4_v1.ckpt\n",
    "\n",
    "# trinart_characters_19_2m vae\n",
    "!ln -s  /content/drive/MyDrive/models/autoencoder_fix_kl-f8-trinart_characters.ckpt /root/invokeai/models/ldm/stable-diffusion-v1/autoencoder_fix_kl-f8-trinart_characters.ckpt\n",
    "!ls -l /root/invokeai/models/ldm/stable-diffusion-v1/autoencoder_fix_kl-f8-trinart_characters.ckpt\n",
    "\n",
    "# anything v3\n",
    "!ln -s  /content/drive/MyDrive/models/Anything-V3.0-pruned-fp16.ckpt /root/invokeai/models/ldm/stable-diffusion-v1/Anything-V3.0-pruned-fp16.ckpt\n",
    "!ls -l /root/invokeai/models/ldm/stable-diffusion-v1/Anything-V3.0-pruned-fp16.ckpt\n",
    "\n",
    "# vae anything v3\n",
    "!ln -s  /content/drive/MyDrive/models/Anything-V3.0.vae.pt /root/invokeai/models/ldm/stable-diffusion-v1/Anything-V3.0.vae.pt\n",
    "!ls -l /root/invokeai/models/ldm/stable-diffusion-v1/Anything-V3.0.vae.pt\n",
    "\n",
    "# vae\n",
    "!ln -s  /content/drive/MyDrive/models/vae-ft-mse-840000-ema-pruned.ckpt /root/invokeai/models/ldm/stable-diffusion-v1/vae-ft-mse-840000-ema-pruned.ckpt\n",
    "!ls -l /root/invokeai/models/ldm/stable-diffusion-v1/vae-ft-mse-840000-ema-pruned.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C826ebQkb_OQ"
   },
   "outputs": [],
   "source": [
    "#@title 06. Running Invoke AI service { display-mode: \"both\" }\n",
    "#@markdown Go to [ngrok](https://dashboard.ngrok.com/get-started/your-authtoken) , and paste your authtoken here.\n",
    "\n",
    "ngrok_token = \"\" #@param {type:\"string\"}\n",
    "nsfw_checker = 0 #@param {type:\"slider\", min:0, max:1, step:1}\n",
    "used_vae = \"vae-ft-mse-840000-ema-pruned\" #@param [\"vae-ft-mse-840000-ema-pruned\"]\n",
    "\n",
    "import os\n",
    "from pyngrok import ngrok\n",
    "\n",
    "ngrok.kill()\n",
    "ngrok.set_auth_token(ngrok_token)\n",
    "public_url = ngrok.connect(9090).public_url\n",
    "print(f'Invoke Ai public url: {public_url}')\n",
    "\n",
    "%cd /home/InvokeAI\n",
    "\n",
    "model_name = \"Stable_Diffusion_15_default\"\n",
    "if used_vae == \"vae-ft-mse-840000-ema-pruned\":\n",
    "    model_name = \"Stable_Diffusion_15_default\"\n",
    "\n",
    "if nsfw_checker:\n",
    "    !source activate invokeai ; python scripts/invoke.py --web --model $model_name\n",
    "else:\n",
    "    !source activate invokeai ; python scripts/invoke.py --web --no-nsfw_checker --model $model_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ckMayfYdkOmF"
   },
   "source": [
    "#### Wait until the local url (`http://localhost:9090`) is available.\n",
    "#### Then click/open public url, it will look something like this ‚û° `http://3877-35-204-151-175.ngrok.io`\n",
    "#### Refresh the page if you see a blank screen\n",
    "---\n",
    "Semoga beruntung üòÄ"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "4534aa43154a8453a45e203b4cc523573eebe5acad81d620b091a3e0a7f47562"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
